{
  "3": {
    "inputs": {
      "seed": [
        "129",
        0
      ],
      "steps": 8,
      "cfg": 1.3,
      "sampler_name": "euler_ancestral",
      "scheduler": "sgm_uniform",
      "denoise": 0.42,
      "model": [
        "65",
        0
      ],
      "positive": [
        "12",
        1
      ],
      "negative": [
        "12",
        2
      ],
      "latent_image": [
        "60",
        0
      ]
    },
    "class_type": "KSampler"
  },
  "6": {
    "inputs": {
      "text": "(looking_at_viewer:1.2)",
      "clip": [
        "609",
        1
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "7": {
    "inputs": {
      "text": "text, watermarkNSFW,lowres,bad anatomy,bad hand,paintings,sketches,(worst quality:2),(low quality:2),(normal quality:2),lowres,((monochrome)),((grayscale)),skin spots,acnes,skin blemishes,age spot,glans,extra fingers,fewer fingers,((watermark:2)),(white letters:1),(multi nipples),bad anatomy,bad hands,text,error,missing fingers,missing arms,missing legs,extra digit,fewer digits,cropped,worst quality,jpeg artifacts,signature,watermark,username,bad feet,Multiple people,blurry,poorly drawn hands,poorly drawn face,mutation,deformed,extra limbs,extra arms,extra legs,malformed limbs,fused fingers,too many fingers,long neck,cross-eyed,mutated hands,polar lowres,bad body,bad proportions,gross proportions,wrong feet bottom render,abdominal stretch,briefs,knickers,kecks,thong,fused fingers,bad body,bad proportion body to legs,wrong toes,extra toes,missing toes,weird toes,2 body,2 pussy,2 upper,2 lower,2 head,3 hand,3 feet,extra long leg,super long leg,mirrored image,mirrored noise",
      "clip": [
        "609",
        1
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "8": {
    "inputs": {
      "samples": [
        "3",
        0
      ],
      "vae": [
        "609",
        2
      ]
    },
    "class_type": "VAEDecode"
  },
  "12": {
    "inputs": {
      "ip_weight": 0.98,
      "cn_strength": 0.98,
      "start_at": 0,
      "end_at": 1,
      "noise": 0.30000000000000004,
      "combine_embeds": "average",
      "instantid": [
        "13",
        0
      ],
      "insightface": [
        "58",
        0
      ],
      "control_net": [
        "14",
        0
      ],
      "image": [
        "175",
        0
      ],
      "model": [
        "609",
        0
      ],
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "image_kps": [
        "43",
        0
      ]
    },
    "class_type": "ApplyInstantIDAdvanced"
  },
  "13": {
    "inputs": {
      "instantid_file": "ip-adapter.bin"
    },
    "class_type": "InstantIDModelLoader"
  },
  "14": {
    "inputs": {
      "control_net_name": "SDXL/instantid/diffusion_pytorch_model.safetensors"
    },
    "class_type": "ControlNetLoader"
  },
  "38": {
    "inputs": {
      "pixels": [
        "43",
        0
      ],
      "vae": [
        "609",
        2
      ]
    },
    "class_type": "VAEEncode"
  },
  "41": {
    "inputs": {
      "detection_hint": "center-1",
      "dilation": 0,
      "threshold": 1,
      "bbox_expansion": 0,
      "mask_hint_threshold": 1,
      "mask_hint_use_negative": "False",
      "sam_model": [
        "62",
        0
      ],
      "segs": [
        "42",
        0
      ],
      "image": [
        "607",
        0
      ]
    },
    "class_type": "SAMDetectorCombined"
  },
  "42": {
    "inputs": {
      "threshold": 0.5,
      "dilation": 10,
      "crop_factor": 1,
      "drop_size": 10,
      "labels": "all",
      "bbox_detector": [
        "56",
        0
      ],
      "image": [
        "607",
        0
      ]
    },
    "class_type": "BboxDetectorSEGS"
  },
  "43": {
    "inputs": {
      "padding_left": [
        "90",
        0
      ],
      "padding_right": [
        "90",
        0
      ],
      "padding_top": [
        "90",
        0
      ],
      "padding_bottom": [
        "90",
        0
      ],
      "return_list": false,
      "image": [
        "607",
        0
      ],
      "mask": [
        "41",
        0
      ]
    },
    "class_type": "Bounded Image Crop with Mask"
  },
  "47": {
    "inputs": {
      "method": "VITMatte(local)",
      "mask_grow": 5,
      "fix_gap": 32,
      "fix_threshold": 0.98,
      "edge_erode": 9,
      "edte_dilate": 9,
      "black_point": 0.11,
      "white_point": 0.99,
      "device": "cuda",
      "max_megapixels": 2,
      "image": [
        "43",
        0
      ],
      "mask": [
        "147",
        0
      ]
    },
    "class_type": "LayerMask: MaskEdgeUltraDetail V2"
  },
  "55": {
    "inputs": {
      "mask": [
        "41",
        0
      ]
    },
    "class_type": "MaskPreview+"
  },
  "56": {
    "inputs": {
      "model_name": "bbox/yolov8n-face-lindevs.pt"
    },
    "class_type": "UltralyticsDetectorProvider"
  },
  "58": {
    "inputs": {
      "provider": "CUDA"
    },
    "class_type": "InstantIDFaceAnalysis"
  },
  "60": {
    "inputs": {
      "samples": [
        "38",
        0
      ],
      "mask": [
        "64",
        0
      ]
    },
    "class_type": "SetLatentNoiseMask"
  },
  "62": {
    "inputs": {
      "model_name": "sam_vit_b_01ec64.pth",
      "device_mode": "Prefer GPU"
    },
    "class_type": "SAMLoader"
  },
  "64": {
    "inputs": {
      "invert_mask": false,
      "grow": 20,
      "blur": 15,
      "mask": [
        "67",
        0
      ]
    },
    "class_type": "LayerMask: MaskGrow"
  },
  "65": {
    "inputs": {
      "model": [
        "124",
        0
      ]
    },
    "class_type": "DifferentialDiffusion"
  },
  "67": {
    "inputs": {
      "height": [
        "68",
        1
      ],
      "width": [
        "68",
        0
      ],
      "interpolation_mode": "bicubic",
      "mask": [
        "166",
        0
      ]
    },
    "class_type": "JWMaskResize"
  },
  "68": {
    "inputs": {
      "image": [
        "43",
        0
      ]
    },
    "class_type": "easy imageSize"
  },
  "90": {
    "inputs": {
      "value": 368
    },
    "class_type": "easy int"
  },
  "92": {
    "inputs": {
      "masks": [
        "47",
        1
      ]
    },
    "class_type": "Mask Fill Holes"
  },
  "96": {
    "inputs": {
      "mask": [
        "92",
        0
      ]
    },
    "class_type": "MaskPreview+"
  },
  "98": {
    "inputs": {
      "mask": [
        "64",
        0
      ]
    },
    "class_type": "MaskPreview+"
  },
  "104": {
    "inputs": {
      "seed": 976572742337147,
      "steps": 8,
      "cfg": 1.4000000000000001,
      "sampler_name": "euler_ancestral",
      "scheduler": "sgm_uniform",
      "denoise": 0.15,
      "model": [
        "65",
        0
      ],
      "positive": [
        "12",
        1
      ],
      "negative": [
        "12",
        2
      ],
      "latent_image": [
        "261",
        0
      ]
    },
    "class_type": "KSampler"
  },
  "105": {
    "inputs": {
      "pixels": [
        "8",
        0
      ],
      "vae": [
        "609",
        2
      ]
    },
    "class_type": "VAEEncode"
  },
  "106": {
    "inputs": {
      "samples": [
        "105",
        0
      ],
      "mask": [
        "64",
        0
      ]
    },
    "class_type": "SetLatentNoiseMask"
  },
  "108": {
    "inputs": {
      "samples": [
        "104",
        0
      ],
      "vae": [
        "609",
        2
      ]
    },
    "class_type": "VAEDecode"
  },
  "124": {
    "inputs": {
      "method": "fidelity",
      "weight": 0.7000000000000001,
      "start_at": 0.05,
      "end_at": 0.683,
      "model": [
        "12",
        0
      ],
      "pulid": [
        "125",
        0
      ],
      "eva_clip": [
        "126",
        0
      ],
      "face_analysis": [
        "127",
        0
      ],
      "image": [
        "175",
        0
      ]
    },
    "class_type": "ApplyPulid"
  },
  "125": {
    "inputs": {
      "pulid_file": "ip-adapter_pulid_sdxl_fp16.safetensors"
    },
    "class_type": "PulidModelLoader"
  },
  "126": {
    "inputs": {},
    "class_type": "PulidEvaClipLoader"
  },
  "127": {
    "inputs": {
      "provider": "CUDA"
    },
    "class_type": "PulidInsightFaceLoader"
  },
  "129": {
    "inputs": {
      "seed": 118893991707790
    },
    "class_type": "easy seed"
  },
  "136": {
    "inputs": {
      "blend_factor": 1,
      "feathering": 4,
      "target": [
        "607",
        0
      ],
      "target_bounds": [
        "43",
        1
      ],
      "source": [
        "177",
        0
      ]
    },
    "class_type": "Bounded Image Blend"
  },
  "145": {
    "inputs": {
      "mask": [
        "41",
        0
      ]
    },
    "class_type": "MaskToImage"
  },
  "146": {
    "inputs": {
      "padding_left": [
        "90",
        0
      ],
      "padding_right": [
        "90",
        0
      ],
      "padding_top": [
        "90",
        0
      ],
      "padding_bottom": [
        "90",
        0
      ],
      "return_list": false,
      "image": [
        "145",
        0
      ],
      "mask": [
        "41",
        0
      ]
    },
    "class_type": "Bounded Image Crop with Mask"
  },
  "147": {
    "inputs": {
      "channel": "red",
      "image": [
        "146",
        0
      ]
    },
    "class_type": "ImageToMask"
  },
  "166": {
    "inputs": {
      "min": 0,
      "max": 0.9,
      "mask": [
        "195",
        0
      ]
    },
    "class_type": "RemapMaskRange"
  },
  "170": {
    "inputs": {
      "seed": 352665211591127,
      "repeat": 3,
      "variation": 0.5,
      "image": [
        "532",
        0
      ]
    },
    "class_type": "ImageRandomTransform+"
  },
  "175": {
    "inputs": {
      "image1": [
        "170",
        0
      ]
    },
    "class_type": "ImpactMakeImageBatch"
  },
  "176": {
    "inputs": {
      "images": [
        "175",
        0
      ]
    },
    "class_type": "PreviewImage"
  },
  "177": {
    "inputs": {
      "method": "mkl",
      "strength": 1,
      "image_ref": [
        "43",
        0
      ],
      "image_target": [
        "108",
        0
      ]
    },
    "class_type": "ColorMatch"
  },
  "194": {
    "inputs": {
      "mask": [
        "92",
        0
      ]
    },
    "class_type": "MaskToImage"
  },
  "195": {
    "inputs": {
      "channel": "red",
      "image": [
        "194",
        0
      ]
    },
    "class_type": "ImageToMask"
  },
  "196": {
    "inputs": {
      "mask": [
        "166",
        0
      ]
    },
    "class_type": "MaskPreview+"
  },
  "261": {
    "inputs": {
      "amount": 1,
      "samples": [
        "106",
        0
      ]
    },
    "class_type": "RepeatLatentBatch"
  },
  "317": {
    "inputs": {
      "enabled": true,
      "swap_model": "inswapper_128.onnx",
      "facedetection": "retinaface_resnet50",
      "face_restore_model": "GFPGANv1.4.pth",
      "face_restore_visibility": 1,
      "codeformer_weight": 0.5,
      "detect_gender_input": "no",
      "detect_gender_source": "no",
      "input_faces_index": "0",
      "source_faces_index": "0",
      "console_log_level": 1,
      "input_image": [
        "43",
        0
      ],
      "source_image": [
        "532",
        0
      ],
      "face_boost": [
        "318",
        0
      ]
    },
    "class_type": "ReActorFaceSwap"
  },
  "318": {
    "inputs": {
      "enabled": true,
      "boost_model": "codeformer-v0.1.0.pth",
      "interpolation": "Bicubic",
      "visibility": 1,
      "codeformer_weight": 0.5,
      "restore_with_main_after": true
    },
    "class_type": "ReActorFaceBoost"
  },
  "337": {
    "inputs": {
      "images": [
        "136",
        0
      ]
    },
    "class_type": "PreviewImage"
  },
  "367": {
    "inputs": {
      "filename_prefix": "Face/人脸脱敏/人脸脱敏",
      "images": [
        "638",
        0
      ]
    },
    "class_type": "SaveImage"
  },
  "413": {
    "inputs": {
      "text1": [
        "636",
        0
      ],
      "separator": ", only Asian face, realistic photos"
    },
    "class_type": "CR Text Concatenate"
  },
  "415": {
    "inputs": {
      "text": [
        "413",
        0
      ],
      "text2": "woman, approximately 25 years old, only Asian face, realistic photos"
    },
    "class_type": "ShowText|pysssss"
  },
  "426": {
    "inputs": {
      "text": [
        "415",
        0
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "430": {
    "inputs": {
      "images": [
        "637",
        0
      ]
    },
    "class_type": "PreviewImage"
  },
  "484": {
    "inputs": {
      "font": "/home/swgz/work/ComfyUI/input/font/Alibaba-PuHuiTi-Heavy.ttf",
      "caption": "1",
      "image": [
        "592",
        0
      ]
    },
    "class_type": "Image Caption"
  },
  "487": {
    "inputs": {
      "font": "/home/swgz/work/ComfyUI/input/font/Alibaba-PuHuiTi-Heavy.ttf",
      "caption": "3",
      "image": [
        "603",
        0
      ]
    },
    "class_type": "Image Caption"
  },
  "495": {
    "inputs": {
      "direction": "right",
      "match_image_size": true,
      "image1": [
        "484",
        0
      ],
      "image2": [
        "499",
        0
      ]
    },
    "class_type": "ImageConcanate"
  },
  "496": {
    "inputs": {
      "direction": "right",
      "match_image_size": true,
      "image1": [
        "495",
        0
      ],
      "image2": [
        "487",
        0
      ]
    },
    "class_type": "ImageConcanate"
  },
  "497": {
    "inputs": {
      "direction": "right",
      "match_image_size": true,
      "image1": [
        "496",
        0
      ],
      "image2": [
        "503",
        0
      ]
    },
    "class_type": "ImageConcanate"
  },
  "499": {
    "inputs": {
      "font": "/home/swgz/work/ComfyUI/input/font/Alibaba-PuHuiTi-Heavy.ttf",
      "caption": "2",
      "image": [
        "136",
        0
      ]
    },
    "class_type": "Image Caption"
  },
  "503": {
    "inputs": {
      "font": "/home/swgz/work/ComfyUI/input/font/Alibaba-PuHuiTi-Heavy.ttf",
      "caption": "4",
      "image": [
        "575",
        0
      ]
    },
    "class_type": "Image Caption"
  },
  "528": {
    "inputs": {
      "seed": 350978690209473,
      "steps": 15,
      "cfg": 3.5,
      "sampler_name": "dpmpp_sde",
      "scheduler": "normal",
      "denoise": 1,
      "model": [
        "609",
        0
      ],
      "positive": [
        "533",
        0
      ],
      "negative": [
        "531",
        0
      ],
      "latent_image": [
        "530",
        0
      ]
    },
    "class_type": "KSampler"
  },
  "530": {
    "inputs": {
      "width": 400,
      "height": 600,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage"
  },
  "531": {
    "inputs": {
      "text": "bad-picture-chill-75v, badhandv4, (worst quality:1.6), (low quality:1.6), (normal quality:1.6), lowres, watermark, monochrome, bad hands",
      "clip": [
        "609",
        1
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "532": {
    "inputs": {
      "samples": [
        "528",
        0
      ],
      "vae": [
        "609",
        2
      ]
    },
    "class_type": "VAEDecode"
  },
  "533": {
    "inputs": {
      "text": [
        "415",
        0
      ],
      "clip": [
        "609",
        1
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "534": {
    "inputs": {
      "images": [
        "532",
        0
      ]
    },
    "class_type": "PreviewImage"
  },
  "541": {
    "inputs": {
      "seed": 441511235005551,
      "steps": 10,
      "cfg": 3.5,
      "sampler_name": "dpmpp_sde",
      "scheduler": "normal",
      "denoise": 1,
      "model": [
        "542",
        0
      ],
      "positive": [
        "546",
        0
      ],
      "negative": [
        "544",
        0
      ],
      "latent_image": [
        "543",
        0
      ]
    },
    "class_type": "KSampler"
  },
  "542": {
    "inputs": {
      "ckpt_name": "realisticVisionV660.safetensors"
    },
    "class_type": "CheckpointLoaderSimple"
  },
  "543": {
    "inputs": {
      "width": 400,
      "height": 600,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage"
  },
  "544": {
    "inputs": {
      "text": "bad-picture-chill-75v, badhandv4, (worst quality:1.6), (low quality:1.6), (normal quality:1.6), lowres, watermark, monochrome, bad hands",
      "clip": [
        "542",
        1
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "545": {
    "inputs": {
      "samples": [
        "541",
        0
      ],
      "vae": [
        "542",
        2
      ]
    },
    "class_type": "VAEDecode"
  },
  "546": {
    "inputs": {
      "text": [
        "415",
        0
      ],
      "clip": [
        "542",
        1
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "547": {
    "inputs": {
      "images": [
        "545",
        0
      ]
    },
    "class_type": "PreviewImage"
  },
  "554": {
    "inputs": {
      "seed": [
        "574",
        0
      ],
      "steps": 8,
      "cfg": 1.3,
      "sampler_name": "euler_ancestral",
      "scheduler": "sgm_uniform",
      "denoise": 0.42,
      "model": [
        "565",
        0
      ],
      "positive": [
        "559",
        1
      ],
      "negative": [
        "559",
        2
      ],
      "latent_image": [
        "564",
        0
      ]
    },
    "class_type": "KSampler"
  },
  "556": {
    "inputs": {
      "text": "(looking_at_viewer:1.2)",
      "clip": [
        "609",
        1
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "557": {
    "inputs": {
      "text": "text, watermarkNSFW,lowres,bad anatomy,bad hand,paintings,sketches,(worst quality:2),(low quality:2),(normal quality:2),lowres,((monochrome)),((grayscale)),skin spots,acnes,skin blemishes,age spot,glans,extra fingers,fewer fingers,((watermark:2)),(white letters:1),(multi nipples),bad anatomy,bad hands,text,error,missing fingers,missing arms,missing legs,extra digit,fewer digits,cropped,worst quality,jpeg artifacts,signature,watermark,username,bad feet,Multiple people,blurry,poorly drawn hands,poorly drawn face,mutation,deformed,extra limbs,extra arms,extra legs,malformed limbs,fused fingers,too many fingers,long neck,cross-eyed,mutated hands,polar lowres,bad body,bad proportions,gross proportions,wrong feet bottom render,abdominal stretch,briefs,knickers,kecks,thong,fused fingers,bad body,bad proportion body to legs,wrong toes,extra toes,missing toes,weird toes,2 body,2 pussy,2 upper,2 lower,2 head,3 hand,3 feet,extra long leg,super long leg,mirrored image,mirrored noise",
      "clip": [
        "609",
        1
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "558": {
    "inputs": {
      "samples": [
        "554",
        0
      ],
      "vae": [
        "609",
        2
      ]
    },
    "class_type": "VAEDecode"
  },
  "559": {
    "inputs": {
      "ip_weight": 0.98,
      "cn_strength": 0.98,
      "start_at": 0,
      "end_at": 1,
      "noise": 0.30000000000000004,
      "combine_embeds": "average",
      "instantid": [
        "560",
        0
      ],
      "insightface": [
        "563",
        0
      ],
      "control_net": [
        "561",
        0
      ],
      "image": [
        "577",
        0
      ],
      "model": [
        "609",
        0
      ],
      "positive": [
        "556",
        0
      ],
      "negative": [
        "557",
        0
      ],
      "image_kps": [
        "43",
        0
      ]
    },
    "class_type": "ApplyInstantIDAdvanced"
  },
  "560": {
    "inputs": {
      "instantid_file": "ip-adapter.bin"
    },
    "class_type": "InstantIDModelLoader"
  },
  "561": {
    "inputs": {
      "control_net_name": "SDXL/instantid/diffusion_pytorch_model.safetensors"
    },
    "class_type": "ControlNetLoader"
  },
  "562": {
    "inputs": {
      "pixels": [
        "43",
        0
      ],
      "vae": [
        "609",
        2
      ]
    },
    "class_type": "VAEEncode"
  },
  "563": {
    "inputs": {
      "provider": "CUDA"
    },
    "class_type": "InstantIDFaceAnalysis"
  },
  "564": {
    "inputs": {
      "samples": [
        "562",
        0
      ],
      "mask": [
        "64",
        0
      ]
    },
    "class_type": "SetLatentNoiseMask"
  },
  "565": {
    "inputs": {
      "model": [
        "570",
        0
      ]
    },
    "class_type": "DifferentialDiffusion"
  },
  "566": {
    "inputs": {
      "seed": 322001247560749,
      "steps": 8,
      "cfg": 1.4000000000000001,
      "sampler_name": "euler_ancestral",
      "scheduler": "sgm_uniform",
      "denoise": 0.15,
      "model": [
        "565",
        0
      ],
      "positive": [
        "559",
        1
      ],
      "negative": [
        "559",
        2
      ],
      "latent_image": [
        "580",
        0
      ]
    },
    "class_type": "KSampler"
  },
  "567": {
    "inputs": {
      "pixels": [
        "558",
        0
      ],
      "vae": [
        "609",
        2
      ]
    },
    "class_type": "VAEEncode"
  },
  "568": {
    "inputs": {
      "samples": [
        "567",
        0
      ],
      "mask": [
        "64",
        0
      ]
    },
    "class_type": "SetLatentNoiseMask"
  },
  "569": {
    "inputs": {
      "samples": [
        "566",
        0
      ],
      "vae": [
        "609",
        2
      ]
    },
    "class_type": "VAEDecode"
  },
  "570": {
    "inputs": {
      "method": "fidelity",
      "weight": 0.7000000000000001,
      "start_at": 0.05,
      "end_at": 0.683,
      "model": [
        "559",
        0
      ],
      "pulid": [
        "571",
        0
      ],
      "eva_clip": [
        "572",
        0
      ],
      "face_analysis": [
        "573",
        0
      ],
      "image": [
        "577",
        0
      ]
    },
    "class_type": "ApplyPulid"
  },
  "571": {
    "inputs": {
      "pulid_file": "ip-adapter_pulid_sdxl_fp16.safetensors"
    },
    "class_type": "PulidModelLoader"
  },
  "572": {
    "inputs": {},
    "class_type": "PulidEvaClipLoader"
  },
  "573": {
    "inputs": {
      "provider": "CUDA"
    },
    "class_type": "PulidInsightFaceLoader"
  },
  "574": {
    "inputs": {
      "seed": 428616128077682
    },
    "class_type": "easy seed"
  },
  "575": {
    "inputs": {
      "blend_factor": 1,
      "feathering": 4,
      "target": [
        "607",
        0
      ],
      "target_bounds": [
        "43",
        1
      ],
      "source": [
        "579",
        0
      ]
    },
    "class_type": "Bounded Image Blend"
  },
  "576": {
    "inputs": {
      "seed": 673793891339625,
      "repeat": 3,
      "variation": 0.5,
      "image": [
        "545",
        0
      ]
    },
    "class_type": "ImageRandomTransform+"
  },
  "577": {
    "inputs": {
      "image1": [
        "576",
        0
      ]
    },
    "class_type": "ImpactMakeImageBatch"
  },
  "578": {
    "inputs": {
      "images": [
        "577",
        0
      ]
    },
    "class_type": "PreviewImage"
  },
  "579": {
    "inputs": {
      "method": "mkl",
      "strength": 1,
      "image_ref": [
        "43",
        0
      ],
      "image_target": [
        "569",
        0
      ]
    },
    "class_type": "ColorMatch"
  },
  "580": {
    "inputs": {
      "amount": 1,
      "samples": [
        "568",
        0
      ]
    },
    "class_type": "RepeatLatentBatch"
  },
  "581": {
    "inputs": {
      "images": [
        "575",
        0
      ]
    },
    "class_type": "PreviewImage"
  },
  "592": {
    "inputs": {
      "blend_factor": 1,
      "feathering": 4,
      "target": [
        "607",
        0
      ],
      "target_bounds": [
        "43",
        1
      ],
      "source": [
        "317",
        0
      ]
    },
    "class_type": "Bounded Image Blend"
  },
  "596": {
    "inputs": {
      "images": [
        "592",
        0
      ]
    },
    "class_type": "PreviewImage"
  },
  "598": {
    "inputs": {
      "enabled": true,
      "swap_model": "inswapper_128.onnx",
      "facedetection": "retinaface_resnet50",
      "face_restore_model": "GFPGANv1.4.pth",
      "face_restore_visibility": 1,
      "codeformer_weight": 0.5,
      "detect_gender_input": "no",
      "detect_gender_source": "no",
      "input_faces_index": "0",
      "source_faces_index": "0",
      "console_log_level": 1,
      "input_image": [
        "43",
        0
      ],
      "source_image": [
        "545",
        0
      ],
      "face_boost": [
        "599",
        0
      ]
    },
    "class_type": "ReActorFaceSwap"
  },
  "599": {
    "inputs": {
      "enabled": true,
      "boost_model": "codeformer-v0.1.0.pth",
      "interpolation": "Bicubic",
      "visibility": 1,
      "codeformer_weight": 0.5,
      "restore_with_main_after": true
    },
    "class_type": "ReActorFaceBoost"
  },
  "603": {
    "inputs": {
      "blend_factor": 1,
      "feathering": 4,
      "target": [
        "607",
        0
      ],
      "target_bounds": [
        "43",
        1
      ],
      "source": [
        "598",
        0
      ]
    },
    "class_type": "Bounded Image Blend"
  },
  "606": {
    "inputs": {
      "images": [
        "603",
        0
      ]
    },
    "class_type": "PreviewImage"
  },
  "607": {
    "inputs": {
      "side_length": 1600,
      "side": "Longest",
      "upscale_method": "nearest-exact",
      "crop": "disabled",
      "image": [
        "637",
        0
      ]
    },
    "class_type": "DF_Image_scale_to_side"
  },
  "609": {
    "inputs": {
      "ckpt_name": "dreamshaperXL_lightningDPMSDE.safetensors"
    },
    "class_type": "CheckpointLoaderSimple"
  },
  "630": {
    "inputs": {
      "side_length": 512,
      "side": "Longest",
      "upscale_method": "nearest-exact",
      "crop": "disabled",
      "image": [
        "637",
        0
      ]
    },
    "class_type": "DF_Image_scale_to_side"
  },
  "636": {
    "inputs": {
      "query": "Only use keywords to output the gender and age of the characters in the image. For example: \"boy, 2 years old\"",
      "debug": "enable",
      "url": "http://127.0.0.1:11434",
      "model": "minicpm-v:latest",
      "keep_alive": 60,
      "format": "text",
      "seed": 81728792,
      "images": [
        "630",
        0
      ]
    },
    "class_type": "OllamaVision"
  },
  "637": {
    "inputs": {
      "url": "https://ts1.cn.mm.bing.net/th/id/R-C.eed97557f689df2382b6a9fc85ed172e?rik=d%2fBN9fsXJ2nz2w&riu=http%3a%2f%2fup.bizhizu.com%2fpic%2fd1%2fb7%2fc1%2fd1b7c1c9d4362b4ed5a433e69a19b383.jpg&ehk=OafBZEPbO07cQidzqmNBh0FzR5lM78gdhBOg7%2bjNdis%3d&risl=&pid=ImgRaw&r=0"
    },
    "class_type": "LoadImagesFromURL"
  },
  "638": {
    "inputs": {
      "direction": "right",
      "match_image_size": true,
      "image1": [
        "640",
        0
      ],
      "image2": [
        "497",
        0
      ]
    },
    "class_type": "ImageConcanate"
  },
  "640": {
    "inputs": {
      "font": "/home/swgz/work/ComfyUI/input/font/Alibaba-PuHuiTi-Heavy.ttf",
      "caption": "原图",
      "image": [
        "607",
        0
      ]
    },
    "class_type": "Image Caption"
  }
}