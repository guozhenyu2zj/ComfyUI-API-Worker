{
  "120": {
    "inputs": {
      "model_name": "sam_vit_b_01ec64.pth",
      "device_mode": "AUTO"
    },
    "class_type": "SAMLoader"
  },
  "121": {
    "inputs": {
      "model_name": "bbox/yolov8n-face-lindevs.pt"
    },
    "class_type": "UltralyticsDetectorProvider"
  },
  "122": {
    "inputs": {
      "bbox_threshold": 0.5,
      "bbox_dilation": 0,
      "crop_factor": 3,
      "drop_size": 10,
      "sub_threshold": 0.5,
      "sub_dilation": 0,
      "sub_bbox_expansion": 0,
      "sam_mask_hint_threshold": 0.7,
      "post_dilation": 0,
      "bbox_detector": [
        "121",
        0
      ],
      "image": [
        "468",
        0
      ],
      "sam_model_opt": [
        "120",
        0
      ]
    },
    "class_type": "ImpactSimpleDetectorSEGS"
  },
  "123": {
    "inputs": {
      "segs": [
        "122",
        0
      ]
    },
    "class_type": "ImpactSEGSToMaskBatch"
  },
  "124": {
    "inputs": {
      "mask": [
        "123",
        0
      ]
    },
    "class_type": "MaskToImage"
  },
  "125": {
    "inputs": {
      "images": [
        "124",
        0
      ]
    },
    "class_type": "easy imageCount"
  },
  "126": {
    "inputs": {
      "start": [
        "162",
        1
      ],
      "length": 1,
      "mask": [
        "123",
        0
      ]
    },
    "class_type": "MaskFromBatch+"
  },
  "127": {
    "inputs": {
      "mask": [
        "126",
        0
      ]
    },
    "class_type": "MaskPreview+"
  },
  "131": {
    "inputs": {
      "images": [
        "124",
        0
      ]
    },
    "class_type": "PreviewImage"
  },
  "132": {
    "inputs": {
      "alpha_mode": true,
      "min_alpha": 0.38,
      "segs": [
        "122",
        0
      ]
    },
    "class_type": "SEGSPreview"
  },
  "133": {
    "inputs": {
      "images": [
        "132",
        0
      ]
    },
    "class_type": "PreviewImage"
  },
  "162": {
    "inputs": {
      "total": [
        "125",
        0
      ],
      "initial_value1": [
        "468",
        0
      ]
    },
    "class_type": "easy forLoopStart"
  },
  "164": {
    "inputs": {
      "flow": [
        "162",
        0
      ],
      "initial_value1": [
        "210",
        0
      ]
    },
    "class_type": "easy forLoopEnd"
  },
  "205": {
    "inputs": {
      "enabled": true,
      "swap_model": "inswapper_128.onnx",
      "facedetection": "retinaface_resnet50",
      "face_restore_model": "GFPGANv1.4.pth",
      "face_restore_visibility": 1,
      "codeformer_weight": 0.5,
      "detect_gender_input": "no",
      "detect_gender_source": "no",
      "input_faces_index": "0",
      "source_faces_index": "0",
      "console_log_level": 1,
      "input_image": [
        "442",
        0
      ],
      "source_image": [
        "479",
        0
      ],
      "face_boost": [
        "206",
        0
      ]
    },
    "class_type": "ReActorFaceSwap"
  },
  "206": {
    "inputs": {
      "enabled": true,
      "boost_model": "codeformer-v0.1.0.pth",
      "interpolation": "Bicubic",
      "visibility": 1,
      "codeformer_weight": 0.5,
      "restore_with_main_after": true
    },
    "class_type": "ReActorFaceBoost"
  },
  "210": {
    "inputs": {
      "blend_factor": 1,
      "feathering": 4,
      "target": [
        "162",
        2
      ],
      "target_bounds": [
        "442",
        1
      ],
      "source": [
        "205",
        0
      ]
    },
    "class_type": "Bounded Image Blend"
  },
  "213": {
    "inputs": {
      "images": [
        "210",
        0
      ]
    },
    "class_type": "PreviewImage"
  },
  "226": {
    "inputs": {
      "text": "5",
      "anything": [
        "125",
        0
      ]
    },
    "class_type": "easy showAnything"
  },
  "309": {
    "inputs": {
      "text": "2",
      "anything": [
        "162",
        1
      ]
    },
    "class_type": "easy showAnything"
  },
  "310": {
    "inputs": {
      "images": [
        "164",
        0
      ]
    },
    "class_type": "PreviewImage"
  },
  "442": {
    "inputs": {
      "padding_left": [
        "497",
        0
      ],
      "padding_right": [
        "497",
        0
      ],
      "padding_top": [
        "497",
        0
      ],
      "padding_bottom": [
        "497",
        0
      ],
      "return_list": false,
      "image": [
        "162",
        2
      ],
      "mask": [
        "126",
        0
      ]
    },
    "class_type": "Bounded Image Crop with Mask"
  },
  "443": {
    "inputs": {
      "method": "VITMatte(local)",
      "mask_grow": 5,
      "fix_gap": 32,
      "fix_threshold": 0.98,
      "edge_erode": 9,
      "edte_dilate": 9,
      "black_point": 0.11,
      "white_point": 0.99,
      "device": "cuda",
      "max_megapixels": 2,
      "image": [
        "442",
        0
      ],
      "mask": [
        "455",
        0
      ]
    },
    "class_type": "LayerMask: MaskEdgeUltraDetail V2"
  },
  "444": {
    "inputs": {
      "mask": [
        "126",
        0
      ]
    },
    "class_type": "MaskPreview+"
  },
  "447": {
    "inputs": {
      "height": [
        "448",
        1
      ],
      "width": [
        "448",
        0
      ],
      "interpolation_mode": "bicubic",
      "mask": [
        "456",
        0
      ]
    },
    "class_type": "JWMaskResize"
  },
  "448": {
    "inputs": {
      "image": [
        "442",
        0
      ]
    },
    "class_type": "easy imageSize"
  },
  "450": {
    "inputs": {
      "masks": [
        "443",
        1
      ]
    },
    "class_type": "Mask Fill Holes"
  },
  "451": {
    "inputs": {
      "mask": [
        "450",
        0
      ]
    },
    "class_type": "MaskPreview+"
  },
  "452": {
    "inputs": {
      "mask": [
        "465",
        0
      ]
    },
    "class_type": "MaskPreview+"
  },
  "453": {
    "inputs": {
      "mask": [
        "126",
        0
      ]
    },
    "class_type": "MaskToImage"
  },
  "454": {
    "inputs": {
      "padding_left": [
        "497",
        0
      ],
      "padding_right": [
        "497",
        0
      ],
      "padding_top": [
        "497",
        0
      ],
      "padding_bottom": [
        "497",
        0
      ],
      "return_list": false,
      "image": [
        "453",
        0
      ],
      "mask": [
        "126",
        0
      ]
    },
    "class_type": "Bounded Image Crop with Mask"
  },
  "455": {
    "inputs": {
      "channel": "red",
      "image": [
        "454",
        0
      ]
    },
    "class_type": "ImageToMask"
  },
  "456": {
    "inputs": {
      "min": 0,
      "max": 0.9,
      "mask": [
        "458",
        0
      ]
    },
    "class_type": "RemapMaskRange"
  },
  "457": {
    "inputs": {
      "mask": [
        "450",
        0
      ]
    },
    "class_type": "MaskToImage"
  },
  "458": {
    "inputs": {
      "channel": "red",
      "image": [
        "457",
        0
      ]
    },
    "class_type": "ImageToMask"
  },
  "459": {
    "inputs": {
      "mask": [
        "456",
        0
      ]
    },
    "class_type": "MaskPreview+"
  },
  "465": {
    "inputs": {
      "invert_mask": false,
      "grow": 20,
      "blur": 15,
      "mask": [
        "447",
        0
      ]
    },
    "class_type": "LayerMask: MaskGrow"
  },
  "468": {
    "inputs": {
      "side_length": 2061,
      "side": "Longest",
      "upscale_method": "nearest-exact",
      "crop": "disabled",
      "image": [
        "502",
        0
      ]
    },
    "class_type": "DF_Image_scale_to_side"
  },
  "470": {
    "inputs": {
      "text1": [
        "484",
        0
      ],
      "separator": ", only Chinese face, realistic photos"
    },
    "class_type": "CR Text Concatenate"
  },
  "471": {
    "inputs": {
      "text": [
        "470",
        0
      ],
      "text2": "boy, young, only Chinese face, realistic photos"
    },
    "class_type": "ShowText|pysssss"
  },
  "472": {
    "inputs": {
      "text": [
        "471",
        0
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "475": {
    "inputs": {
      "seed": 441511235005551,
      "steps": 10,
      "cfg": 3.5,
      "sampler_name": "dpmpp_sde",
      "scheduler": "normal",
      "denoise": 1,
      "model": [
        "476",
        0
      ],
      "positive": [
        "480",
        0
      ],
      "negative": [
        "478",
        0
      ],
      "latent_image": [
        "477",
        0
      ]
    },
    "class_type": "KSampler"
  },
  "476": {
    "inputs": {
      "ckpt_name": "realisticVisionV660.safetensors"
    },
    "class_type": "CheckpointLoaderSimple"
  },
  "477": {
    "inputs": {
      "width": 360,
      "height": 360,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage"
  },
  "478": {
    "inputs": {
      "text": "bad-picture-chill-75v, badhandv4, (worst quality:1.6), (low quality:1.6), (normal quality:1.6), lowres, watermark, monochrome, bad hands",
      "clip": [
        "476",
        1
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "479": {
    "inputs": {
      "samples": [
        "475",
        0
      ],
      "vae": [
        "476",
        2
      ]
    },
    "class_type": "VAEDecode"
  },
  "480": {
    "inputs": {
      "text": [
        "471",
        0
      ],
      "clip": [
        "476",
        1
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "481": {
    "inputs": {
      "images": [
        "479",
        0
      ]
    },
    "class_type": "PreviewImage"
  },
  "484": {
    "inputs": {
      "query": "Only use keywords to output the gender and age of the characters in the image. For example: \"boy, 2 years old\"",
      "debug": "enable",
      "url": "http://127.0.0.1:11434",
      "model": "minicpm-v:latest",
      "keep_alive": 60,
      "format": "text",
      "seed": 838892462,
      "images": [
        "442",
        0
      ]
    },
    "class_type": "OllamaVision"
  },
  "493": {
    "inputs": {
      "facedetection": "retinaface_resnet50",
      "image": [
        "468",
        0
      ]
    },
    "class_type": "CropFace"
  },
  "494": {
    "inputs": {
      "image": [
        "493",
        0
      ]
    },
    "class_type": "GetImageSize+"
  },
  "495": {
    "inputs": {
      "value": [
        "494",
        0
      ]
    },
    "class_type": "Int-🔬"
  },
  "496": {
    "inputs": {
      "text": "85",
      "anything": [
        "497",
        0
      ]
    },
    "class_type": "easy showAnything"
  },
  "497": {
    "inputs": {
      "a": [
        "495",
        0
      ],
      "b": 6,
      "operation": "divide"
    },
    "class_type": "easy mathInt"
  },
  "499": {
    "inputs": {
      "images": [
        "493",
        0
      ]
    },
    "class_type": "PreviewImage"
  },
  "501": {
    "inputs": {
      "images": [
        "442",
        0
      ]
    },
    "class_type": "PreviewImage"
  },
  "502": {
    "inputs": {
      "url": "https://www.jiaphoto.net/Public/upload/2019-06-18/5d085600a806e.jpg"
    },
    "class_type": "LoadImagesFromURL"
  },
  "503": {
    "inputs": {
      "filename_prefix": "Face/多重人脸快速脱敏/多重人脸快速脱敏",
      "images": [
        "210",
        0
      ]
    },
    "class_type": "SaveImage"
  }
}