{
  "170": {
    "inputs": {
      "seed": 352665211591127,
      "repeat": 3,
      "variation": 0.5,
      "image": [
        "911",
        0
      ]
    },
    "class_type": "ImageRandomTransform+"
  },
  "175": {
    "inputs": {
      "image1": [
        "170",
        0
      ]
    },
    "class_type": "ImpactMakeImageBatch"
  },
  "176": {
    "inputs": {
      "images": [
        "175",
        0
      ]
    },
    "class_type": "PreviewImage"
  },
  "752": {
    "inputs": {
      "ckpt_name": "dreamshaperXL_lightningDPMSDE.safetensors"
    },
    "class_type": "CheckpointLoaderSimple"
  },
  "821": {
    "inputs": {
      "images": [
        "839",
        0
      ]
    },
    "class_type": "PreviewImage"
  },
  "822": {
    "inputs": {
      "model_name": "sam_vit_b_01ec64.pth",
      "device_mode": "AUTO"
    },
    "class_type": "SAMLoader"
  },
  "823": {
    "inputs": {
      "model_name": "bbox/yolov8n-face-lindevs.pt"
    },
    "class_type": "UltralyticsDetectorProvider"
  },
  "824": {
    "inputs": {
      "bbox_threshold": 0.5,
      "bbox_dilation": 0,
      "crop_factor": 3,
      "drop_size": 10,
      "sub_threshold": 0.5,
      "sub_dilation": 0,
      "sub_bbox_expansion": 0,
      "sam_mask_hint_threshold": 0.7,
      "post_dilation": 0,
      "bbox_detector": [
        "823",
        0
      ],
      "image": [
        "860",
        0
      ],
      "sam_model_opt": [
        "822",
        0
      ]
    },
    "class_type": "ImpactSimpleDetectorSEGS"
  },
  "825": {
    "inputs": {
      "segs": [
        "824",
        0
      ]
    },
    "class_type": "ImpactSEGSToMaskBatch"
  },
  "826": {
    "inputs": {
      "mask": [
        "825",
        0
      ]
    },
    "class_type": "MaskToImage"
  },
  "827": {
    "inputs": {
      "images": [
        "826",
        0
      ]
    },
    "class_type": "easy imageCount"
  },
  "828": {
    "inputs": {
      "start": [
        "865",
        0
      ],
      "length": 1,
      "mask": [
        "825",
        0
      ]
    },
    "class_type": "MaskFromBatch+"
  },
  "829": {
    "inputs": {
      "mask": [
        "828",
        0
      ]
    },
    "class_type": "MaskPreview+"
  },
  "831": {
    "inputs": {
      "images": [
        "826",
        0
      ]
    },
    "class_type": "PreviewImage"
  },
  "832": {
    "inputs": {
      "alpha_mode": true,
      "min_alpha": 0.38,
      "segs": [
        "824",
        0
      ]
    },
    "class_type": "SEGSPreview"
  },
  "833": {
    "inputs": {
      "images": [
        "832",
        0
      ]
    },
    "class_type": "PreviewImage"
  },
  "839": {
    "inputs": {
      "padding_left": [
        "863",
        0
      ],
      "padding_right": [
        "863",
        0
      ],
      "padding_top": [
        "863",
        0
      ],
      "padding_bottom": [
        "863",
        0
      ],
      "return_list": false,
      "image": [
        "860",
        0
      ],
      "mask": [
        "828",
        0
      ]
    },
    "class_type": "Bounded Image Crop with Mask"
  },
  "840": {
    "inputs": {
      "method": "VITMatte(local)",
      "mask_grow": 5,
      "fix_gap": 32,
      "fix_threshold": 0.98,
      "edge_erode": 9,
      "edte_dilate": 9,
      "black_point": 0.11,
      "white_point": 0.99,
      "device": "cuda",
      "max_megapixels": 2,
      "image": [
        "839",
        0
      ],
      "mask": [
        "849",
        0
      ]
    },
    "class_type": "LayerMask: MaskEdgeUltraDetail V2"
  },
  "841": {
    "inputs": {
      "mask": [
        "828",
        0
      ]
    },
    "class_type": "MaskPreview+"
  },
  "842": {
    "inputs": {
      "height": [
        "843",
        1
      ],
      "width": [
        "843",
        0
      ],
      "interpolation_mode": "bicubic",
      "mask": [
        "850",
        0
      ]
    },
    "class_type": "JWMaskResize"
  },
  "843": {
    "inputs": {
      "image": [
        "839",
        0
      ]
    },
    "class_type": "easy imageSize"
  },
  "844": {
    "inputs": {
      "masks": [
        "840",
        1
      ]
    },
    "class_type": "Mask Fill Holes"
  },
  "845": {
    "inputs": {
      "mask": [
        "844",
        0
      ]
    },
    "class_type": "MaskPreview+"
  },
  "846": {
    "inputs": {
      "mask": [
        "859",
        0
      ]
    },
    "class_type": "MaskPreview+"
  },
  "847": {
    "inputs": {
      "mask": [
        "828",
        0
      ]
    },
    "class_type": "MaskToImage"
  },
  "848": {
    "inputs": {
      "padding_left": [
        "863",
        0
      ],
      "padding_right": [
        "863",
        0
      ],
      "padding_top": [
        "863",
        0
      ],
      "padding_bottom": [
        "863",
        0
      ],
      "return_list": false,
      "image": [
        "847",
        0
      ],
      "mask": [
        "828",
        0
      ]
    },
    "class_type": "Bounded Image Crop with Mask"
  },
  "849": {
    "inputs": {
      "channel": "red",
      "image": [
        "848",
        0
      ]
    },
    "class_type": "ImageToMask"
  },
  "850": {
    "inputs": {
      "min": 0,
      "max": 0.9,
      "mask": [
        "852",
        0
      ]
    },
    "class_type": "RemapMaskRange"
  },
  "851": {
    "inputs": {
      "mask": [
        "844",
        0
      ]
    },
    "class_type": "MaskToImage"
  },
  "852": {
    "inputs": {
      "channel": "red",
      "image": [
        "851",
        0
      ]
    },
    "class_type": "ImageToMask"
  },
  "853": {
    "inputs": {
      "mask": [
        "850",
        0
      ]
    },
    "class_type": "MaskPreview+"
  },
  "859": {
    "inputs": {
      "invert_mask": false,
      "grow": 20,
      "blur": 15,
      "mask": [
        "842",
        0
      ]
    },
    "class_type": "LayerMask: MaskGrow"
  },
  "860": {
    "inputs": {
      "side_length": 2045,
      "side": "Longest",
      "upscale_method": "nearest-exact",
      "crop": "disabled",
      "image": [
        "920",
        0
      ]
    },
    "class_type": "DF_Image_scale_to_side"
  },
  "863": {
    "inputs": {
      "Number": "368"
    },
    "class_type": "Int"
  },
  "865": {
    "inputs": {
      "Number": "1"
    },
    "class_type": "Int"
  },
  "867": {
    "inputs": {
      "seed": [
        "886",
        0
      ],
      "steps": 8,
      "cfg": 1.3,
      "sampler_name": "euler_ancestral",
      "scheduler": "sgm_uniform",
      "denoise": 0.42,
      "model": [
        "877",
        0
      ],
      "positive": [
        "871",
        1
      ],
      "negative": [
        "871",
        2
      ],
      "latent_image": [
        "876",
        0
      ]
    },
    "class_type": "KSampler"
  },
  "868": {
    "inputs": {
      "text": "(looking_at_viewer:1.2)",
      "clip": [
        "752",
        1
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "869": {
    "inputs": {
      "text": "text, watermarkNSFW,lowres,bad anatomy,bad hand,paintings,sketches,(worst quality:2),(low quality:2),(normal quality:2),lowres,((monochrome)),((grayscale)),skin spots,acnes,skin blemishes,age spot,glans,extra fingers,fewer fingers,((watermark:2)),(white letters:1),(multi nipples),bad anatomy,bad hands,text,error,missing fingers,missing arms,missing legs,extra digit,fewer digits,cropped,worst quality,jpeg artifacts,signature,watermark,username,bad feet,Multiple people,blurry,poorly drawn hands,poorly drawn face,mutation,deformed,extra limbs,extra arms,extra legs,malformed limbs,fused fingers,too many fingers,long neck,cross-eyed,mutated hands,polar lowres,bad body,bad proportions,gross proportions,wrong feet bottom render,abdominal stretch,briefs,knickers,kecks,thong,fused fingers,bad body,bad proportion body to legs,wrong toes,extra toes,missing toes,weird toes,2 body,2 pussy,2 upper,2 lower,2 head,3 hand,3 feet,extra long leg,super long leg,mirrored image,mirrored noise",
      "clip": [
        "752",
        1
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "870": {
    "inputs": {
      "samples": [
        "867",
        0
      ],
      "vae": [
        "752",
        2
      ]
    },
    "class_type": "VAEDecode"
  },
  "871": {
    "inputs": {
      "ip_weight": 0.98,
      "cn_strength": 0.98,
      "start_at": 0,
      "end_at": 1,
      "noise": 0.30000000000000004,
      "combine_embeds": "average",
      "instantid": [
        "872",
        0
      ],
      "insightface": [
        "875",
        0
      ],
      "control_net": [
        "873",
        0
      ],
      "image": [
        "175",
        0
      ],
      "model": [
        "752",
        0
      ],
      "positive": [
        "868",
        0
      ],
      "negative": [
        "869",
        0
      ],
      "image_kps": [
        "839",
        0
      ]
    },
    "class_type": "ApplyInstantIDAdvanced"
  },
  "872": {
    "inputs": {
      "instantid_file": "ip-adapter.bin"
    },
    "class_type": "InstantIDModelLoader"
  },
  "873": {
    "inputs": {
      "control_net_name": "SDXL/instantid/diffusion_pytorch_model.safetensors"
    },
    "class_type": "ControlNetLoader"
  },
  "874": {
    "inputs": {
      "pixels": [
        "839",
        0
      ],
      "vae": [
        "752",
        2
      ]
    },
    "class_type": "VAEEncode"
  },
  "875": {
    "inputs": {
      "provider": "CUDA"
    },
    "class_type": "InstantIDFaceAnalysis"
  },
  "876": {
    "inputs": {
      "samples": [
        "874",
        0
      ],
      "mask": [
        "859",
        0
      ]
    },
    "class_type": "SetLatentNoiseMask"
  },
  "877": {
    "inputs": {
      "model": [
        "882",
        0
      ]
    },
    "class_type": "DifferentialDiffusion"
  },
  "878": {
    "inputs": {
      "seed": 976572742337147,
      "steps": 8,
      "cfg": 1.4000000000000001,
      "sampler_name": "euler_ancestral",
      "scheduler": "sgm_uniform",
      "denoise": 0.15,
      "model": [
        "877",
        0
      ],
      "positive": [
        "871",
        1
      ],
      "negative": [
        "871",
        2
      ],
      "latent_image": [
        "890",
        0
      ]
    },
    "class_type": "KSampler"
  },
  "879": {
    "inputs": {
      "pixels": [
        "870",
        0
      ],
      "vae": [
        "752",
        2
      ]
    },
    "class_type": "VAEEncode"
  },
  "880": {
    "inputs": {
      "samples": [
        "879",
        0
      ],
      "mask": [
        "859",
        0
      ]
    },
    "class_type": "SetLatentNoiseMask"
  },
  "881": {
    "inputs": {
      "samples": [
        "878",
        0
      ],
      "vae": [
        "752",
        2
      ]
    },
    "class_type": "VAEDecode"
  },
  "882": {
    "inputs": {
      "method": "fidelity",
      "weight": 0.7000000000000001,
      "start_at": 0.05,
      "end_at": 0.683,
      "model": [
        "871",
        0
      ],
      "pulid": [
        "883",
        0
      ],
      "eva_clip": [
        "884",
        0
      ],
      "face_analysis": [
        "885",
        0
      ],
      "image": [
        "175",
        0
      ]
    },
    "class_type": "ApplyPulid"
  },
  "883": {
    "inputs": {
      "pulid_file": "ip-adapter_pulid_sdxl_fp16.safetensors"
    },
    "class_type": "PulidModelLoader"
  },
  "884": {
    "inputs": {},
    "class_type": "PulidEvaClipLoader"
  },
  "885": {
    "inputs": {
      "provider": "CUDA"
    },
    "class_type": "PulidInsightFaceLoader"
  },
  "886": {
    "inputs": {
      "seed": 118893991707790
    },
    "class_type": "easy seed"
  },
  "887": {
    "inputs": {
      "blend_factor": 1,
      "feathering": 4,
      "target": [
        "860",
        0
      ],
      "target_bounds": [
        "839",
        1
      ],
      "source": [
        "889",
        0
      ]
    },
    "class_type": "Bounded Image Blend"
  },
  "889": {
    "inputs": {
      "method": "mkl",
      "strength": 1,
      "image_ref": [
        "839",
        0
      ],
      "image_target": [
        "881",
        0
      ]
    },
    "class_type": "ColorMatch"
  },
  "890": {
    "inputs": {
      "amount": 1,
      "samples": [
        "880",
        0
      ]
    },
    "class_type": "RepeatLatentBatch"
  },
  "891": {
    "inputs": {
      "images": [
        "887",
        0
      ]
    },
    "class_type": "PreviewImage"
  },
  "902": {
    "inputs": {
      "filename_prefix": "Face/多重人脸细致脱敏/多重人脸细致脱敏",
      "images": [
        "887",
        0
      ]
    },
    "class_type": "SaveImage"
  },
  "903": {
    "inputs": {
      "text1": [
        "914",
        0
      ],
      "separator": ", only Chinese face, realistic photos"
    },
    "class_type": "CR Text Concatenate"
  },
  "904": {
    "inputs": {
      "text": [
        "903",
        0
      ],
      "text2": "\"boy, 8 years old, only Chinese face, realistic photos"
    },
    "class_type": "ShowText|pysssss"
  },
  "905": {
    "inputs": {
      "text": [
        "904",
        0
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "907": {
    "inputs": {
      "seed": 441511235005551,
      "steps": 10,
      "cfg": 3.5,
      "sampler_name": "dpmpp_sde",
      "scheduler": "normal",
      "denoise": 1,
      "model": [
        "908",
        0
      ],
      "positive": [
        "912",
        0
      ],
      "negative": [
        "910",
        0
      ],
      "latent_image": [
        "909",
        0
      ]
    },
    "class_type": "KSampler"
  },
  "908": {
    "inputs": {
      "ckpt_name": "majicmix7.safetensors"
    },
    "class_type": "CheckpointLoaderSimple"
  },
  "909": {
    "inputs": {
      "width": 512,
      "height": 512,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage"
  },
  "910": {
    "inputs": {
      "text": "bad-picture-chill-75v, badhandv4, (worst quality:1.6), (low quality:1.6), (normal quality:1.6), lowres, watermark, monochrome, bad hands",
      "clip": [
        "908",
        1
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "911": {
    "inputs": {
      "samples": [
        "907",
        0
      ],
      "vae": [
        "908",
        2
      ]
    },
    "class_type": "VAEDecode"
  },
  "912": {
    "inputs": {
      "text": [
        "904",
        0
      ],
      "clip": [
        "908",
        1
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "913": {
    "inputs": {
      "images": [
        "911",
        0
      ]
    },
    "class_type": "PreviewImage"
  },
  "914": {
    "inputs": {
      "query": "Only use keywords to output the gender and age of the characters in the image. For example: \"boy, 2 years old\"",
      "debug": "enable",
      "url": "http://127.0.0.1:11434",
      "model": "minicpm-v:latest",
      "keep_alive": 60,
      "format": "text",
      "seed": 1215215387,
      "images": [
        "918",
        0
      ]
    },
    "class_type": "OllamaVision"
  },
  "916": {
    "inputs": {
      "images": [
        "918",
        0
      ]
    },
    "class_type": "PreviewImage"
  },
  "918": {
    "inputs": {
      "padding_left": 32,
      "padding_right": 32,
      "padding_top": 32,
      "padding_bottom": 32,
      "return_list": false,
      "image": [
        "860",
        0
      ],
      "mask": [
        "828",
        0
      ]
    },
    "class_type": "Bounded Image Crop with Mask"
  },
  "920": {
    "inputs": {
      "url": "https://www.jiaphoto.net/Public/upload/2019-06-18/5d085600a806e.jpg"
    },
    "class_type": "LoadImagesFromURL"
  }
}